{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[{"file_id":"1rmgd1zUS6d8DcQlAv85-5RxwB1wnfnwB","timestamp":1732136661830},{"file_id":"https://github.com/NeuralFalconYT/MaskGCT-TTS-Colab/blob/main/MaskGCT_TTS.ipynb","timestamp":1732063731292}],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["Credit:\n","[MaskGCT GitHub](https://github.com/open-mmlab/Amphion/tree/main/models/tts/maskgct)"],"metadata":{"id":"SMR867ZiAb2c"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"YLskI67FihE9"},"outputs":[],"source":["from google.colab import drive\n","import torch\n","\n","drive.mount('/content')\n","#torch.save(model.state_dict(), '/content/drive/MaskGCT/model.pth')\n","#model.load_state_dict(torch.load('/content/drive/MaskGCT/model.pth'))\n","\n","base_path=\"/content/drive\"\n","# base_path=\".\" #for  local devices"]},{"cell_type":"code","source":["#@title Install MaskGCT TTS and Restart Session [Cancel All Pop-Up] [Wait For 6 Minutes]\n","!rm -rf $base_path/Amphion\n","%cd $base_path\n","# !git clone https://github.com/open-mmlab/Amphion.git\n","!git clone https://github.com/NeuralFalconYT/Amphion\n","!pip install setuptools ruamel.yaml tqdm\n","# pip install tensorboard tensorboardX torch==2.0.1\n","!pip install transformers===4.41.1\n","!pip install -U encodec\n","!pip install black==24.1.1\n","!pip install oss2\n","!sudo apt-get install espeak-ng\n","!pip install phonemizer\n","!pip install g2p_en\n","!pip install accelerate==0.31.0\n","!pip install funasr zhconv zhon modelscope\n","# pip install git+https://github.com/lhotse-speech/lhotse\n","!pip install timm\n","!pip install jieba cn2an\n","!pip install unidecode\n","!pip install -U cos-python-sdk-v5\n","!pip install pypinyin\n","!pip install jiwer\n","!pip install omegaconf\n","!pip install pyworld\n","!pip install py3langid==0.2.2 LangSegment\n","# !pip install onnxruntime\n","!pip install onnxruntime-gpu==1.20.0\n","!pip install pyopenjtalk\n","!pip install pykakasi\n","!pip install -U openai-whisper\n","!pip install json5\n","!pip install pydub\n","!pip install gradio\n","# !pip install nltk\n","!pip install nltk==3.8.1\n","from IPython.display import clear_output\n","clear_output()\n","import time\n","time.sleep(5)\n","import os\n","os.kill(os.getpid(), 9)"],"metadata":{"id":"uvOlgRb-klej"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["After auto-restarting the session, run from the next cell."],"metadata":{"id":"hWwe4qauAK8R"}},{"cell_type":"code","source":["base_path=\"/content\"\n","# base_path=\".\" #for  local devices\n","project_path=f\"{base_path}/Amphion/\""],"metadata":{"id":"O5EQ4XeSjTpT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title Download Model\n","import locale\n","locale.getpreferredencoding = lambda: \"UTF-8\"\n","\n","import subprocess\n","import torch\n","import os\n","from pydub import AudioSegment\n","import uuid\n","import re\n","from huggingface_hub import hf_hub_download\n","semantic_code_ckpt,codec_encoder_ckpt,codec_decoder_ckpt,t2s_model_ckpt,s2a_1layer_ckpt,s2a_full_ckpt=None,None,None,None,None,None\n","def download_checkpoint():\n","  # download checkpoint\n","  global semantic_code_ckpt,codec_encoder_ckpt,codec_decoder_ckpt,t2s_model_ckpt,s2a_1layer_ckpt,s2a_full_ckpt\n","  # download semantic codec ckpt\n","  semantic_code_ckpt = hf_hub_download(\n","      \"amphion/MaskGCT\", filename=\"semantic_codec/model.safetensors\"\n","  )\n","  # download acoustic codec ckpt\n","  codec_encoder_ckpt = hf_hub_download(\n","      \"amphion/MaskGCT\", filename=\"acoustic_codec/model.safetensors\"\n","  )\n","  codec_decoder_ckpt = hf_hub_download(\n","      \"amphion/MaskGCT\", filename=\"acoustic_codec/model_1.safetensors\"\n","  )\n","  # download t2s model ckpt\n","  t2s_model_ckpt = hf_hub_download(\n","      \"amphion/MaskGCT\", filename=\"t2s_model/model.safetensors\"\n","  )\n","  # download s2a model ckpt\n","  s2a_1layer_ckpt = hf_hub_download(\n","      \"amphion/MaskGCT\", filename=\"s2a_model/s2a_model_1layer/model.safetensors\"\n","  )\n","  s2a_full_ckpt = hf_hub_download(\n","      \"amphion/MaskGCT\", filename=\"s2a_model/s2a_model_full/model.safetensors\"\n","  )\n","download_checkpoint()\n","from IPython.display import clear_output\n","clear_output()"],"metadata":{"id":"pOX_-UHSFdwO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title Utils\n","\n","def get_max_gpu_memory():\n","    if torch.cuda.is_available():\n","        device = torch.device(\"cuda:0\")\n","        total_memory = torch.cuda.get_device_properties(device).total_memory\n","        max_gpu_memory_gb = round(total_memory / (1024 ** 3), 2)  # Convert to GB and round to 2 decimal places\n","        # print(f\"Maximum GPU memory available: {max_gpu_memory_gb} GB\")\n","        return max_gpu_memory_gb\n","    else:\n","        print(\"CUDA is not available.\")\n","        return None\n","\n","def is_gpu_memory_over_limit(limit_gb=14.5):\n","    limit_gb=get_max_gpu_memory()-0.60\n","    if limit_gb==None:\n","      return False\n","    # Run nvidia-smi and capture the output\n","    result = subprocess.run(['nvidia-smi', '--query-gpu=memory.used', '--format=csv,nounits,noheader'],\n","                            stdout=subprocess.PIPE, text=True)\n","\n","    # Split the result into lines (for each GPU if there are multiple)\n","    memory_used_mb_list = result.stdout.strip().splitlines()\n","\n","    # Convert memory used from MB to GB and check each GPU's memory usage\n","    for i, memory_used_mb in enumerate(memory_used_mb_list):\n","        memory_used_gb = int(memory_used_mb) / 1024.0\n","        # print(f\"GPU {i}: Current memory allocated: {memory_used_gb:.2f} GB\")\n","        if memory_used_gb > limit_gb:\n","            # print(f\"GPU {i} memory usage exceeds {limit_gb} GB.\")\n","            return True\n","\n","    # print(\"GPU memory usage is within safe limits.\")\n","    return False\n","\n","\n","\n","\n","def is_audio_duration_greater_than(audio_path, max_duration):\n","    \"\"\"Check if audio duration is greater than max_duration.\"\"\"\n","    try:\n","        audio = AudioSegment.from_file(audio_path)\n","        duration = len(audio) / 1000  # Duration in seconds\n","        return duration > max_duration\n","    except Exception as e:\n","        print(f\"Error loading audio file: {e}\")\n","        return False\n","\n","def trim_and_convert_audio(input_audio_path, max_duration=30):\n","    \"\"\"Trim audio to max_duration and convert to 16,000 Hz.\"\"\"\n","    global base_path,reference_folder\n","\n","\n","    audio = AudioSegment.from_file(input_audio_path)\n","    trimmed_audio = audio[:max_duration * 1000] if len(audio) / 1000 > max_duration else audio\n","    # trimmed_audio = trimmed_audio.set_frame_rate(24000)\n","\n","    # Generate output file name\n","    base_name = os.path.splitext(os.path.basename(input_audio_path))[0]\n","    output_file = f\"{reference_folder}/{base_name}_final.wav\"\n","    trimmed_audio.export(output_file, format=\"wav\")\n","\n","    return output_file\n","\n","def process_audio(reference_audio, max_duration=15):\n","    global reference_folder\n","    \"\"\"Process audio: trim if longer than max_duration and ensure 16,000 Hz.\"\"\"\n","    if is_audio_duration_greater_than(reference_audio, max_duration):\n","        return trim_and_convert_audio(reference_audio, max_duration)\n","\n","    # If audio is less than or equal to max_duration, convert to 16,000 Hz\n","    audio = AudioSegment.from_file(reference_audio)\n","    # audio = audio.set_frame_rate(24000)\n","\n","    # Generate output file name\n","    base_name = os.path.splitext(os.path.basename(reference_audio))[0]\n","    output_file = f\"{reference_folder}/{base_name}_final.wav\"\n","    audio.export(output_file, format=\"wav\")\n","\n","    return output_file\n","\n","def clean_file_name(file_path):\n","    # Get the base file name and extension\n","    file_name = os.path.basename(file_path)\n","    file_name, file_extension = os.path.splitext(file_name)\n","\n","    # Replace non-alphanumeric characters with an underscore\n","    cleaned = re.sub(r'[^a-zA-Z\\d]+', '_', file_name)\n","\n","    # Remove any multiple underscores\n","    clean_file_name = re.sub(r'_+', '_', cleaned).strip('_')\n","\n","    # Generate a random UUID for uniqueness\n","    random_uuid = uuid.uuid4().hex[:6]\n","\n","    # Combine cleaned file name with the original extension\n","    clean_file_path = os.path.join(os.path.dirname(file_path), clean_file_name + f\"_{random_uuid}\" + file_extension)\n","\n","    return clean_file_path\n","\n","\n","def tts_file_name(text):\n","    global save_audio_folder\n","    if text.endswith(\".\"):\n","        text = text[:-1]\n","    text = text.lower()\n","    text = text.strip()\n","    text = text.replace(\" \",\"_\")\n","    truncated_text = text[:25] if len(text) > 25 else text if len(text) > 0 else \"empty\"\n","    file_name = f\"{save_audio_folder}/{truncated_text}.wav\"\n","    file_name=clean_file_name(file_name)\n","    return file_name\n","\n","import nltk\n","nltk.download('punkt')\n","from nltk.tokenize import sent_tokenize\n","\n","def merge_audio(audio_list, save_path):\n","    # Initialize an empty audio segment\n","    merged_audio = AudioSegment.empty()\n","\n","    # Loop through the list of audio files\n","    for audio_file in audio_list:\n","        # Load each audio file\n","        audio_segment = AudioSegment.from_wav(audio_file)\n","        # Append to the merged audio segment\n","        merged_audio += audio_segment\n","\n","    # Export the merged audio to the specified save path\n","    merged_audio.export(save_path, format=\"wav\")\n","\n","def chunks_sentences(paragraph, join_limit=1):\n","    sentences = sent_tokenize(paragraph)\n","    # Initialize an empty list to store the new sentences\n","    new_sentences = []\n","\n","    # Iterate through the list of sentences in steps of 'join_limit'\n","    for i in range(0, len(sentences), join_limit):\n","        # Join the sentences with a space between them\n","        new_sentence = ' '.join(sentences[i:i + join_limit])\n","        new_sentences.append(new_sentence)\n","    return new_sentences\n","\n","\n","\n","from IPython.display import clear_output\n","clear_output()"],"metadata":{"cellView":"form","id":"2X3Ijdf7zv5e"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title load Model\n","import os\n","os.chdir(project_path)\n","\n","import gc\n","import time\n","import torch\n","import safetensors\n","import soundfile as sf\n","from models.tts.maskgct.maskgct_utils import *\n","from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline\n","import shutil\n","device = torch.device(\"cuda:0\")\n","\n","# Define global variables for models\n","semantic_model, semantic_codec, codec_encoder, codec_decoder, t2s_model = None, None, None, None, None\n","s2a_model_1layer, s2a_model_full, semantic_mean, semantic_std = None, None, None, None\n","whisper_pipe,whisper_model=None,None\n","semantic_code_ckpt,codec_encoder_ckpt,codec_decoder_ckpt,t2s_model_ckpt,s2a_1layer_ckpt,s2a_full_ckpt\n","\n","def clear_model_cache():\n","    \"\"\"Clear global variables and GPU memory.\"\"\"\n","    global semantic_model, semantic_codec, codec_encoder, codec_decoder\n","    global t2s_model, s2a_model_1layer, s2a_model_full, semantic_mean, semantic_std\n","    global whisper_pipe, whisper_model\n","\n","    # List of all global model variables\n","    model_vars = [\n","        \"semantic_model\", \"semantic_codec\", \"codec_encoder\", \"codec_decoder\",\n","        \"t2s_model\", \"s2a_model_1layer\", \"s2a_model_full\", \"semantic_mean\", \"semantic_std\",\n","        \"whisper_pipe\", \"whisper_model\"\n","    ]\n","\n","    try:\n","        # Delete and set each variable to None\n","        for var in model_vars:\n","            # print(f\"Variable: {var} before clearing: {globals()[var]}\")  # Print before clearing\n","            if globals()[var] is not None:\n","                del globals()[var]\n","                globals()[var] = None\n","            # print(f\"Variable: {var} after clearing: {globals()[var]}\")  # Print after clearing\n","\n","        # Clear Python garbage and GPU cache\n","        gc.collect()\n","        torch.cuda.empty_cache()\n","\n","    except Exception as e:\n","        print(f\"Error while clearing cache: {e}\")  # Print any error that occurs\n","\n","\n","# Load Whisper model\n","\n","def load_model():\n","    \"\"\"Load models into GPU memory, clearing old models first.\"\"\"\n","    global semantic_model, semantic_codec, codec_encoder, codec_decoder\n","    global t2s_model, s2a_model_1layer, s2a_model_full, semantic_mean, semantic_std\n","    global whisper_pipe,whisper_model\n","    global semantic_code_ckpt,codec_encoder_ckpt,codec_decoder_ckpt,t2s_model_ckpt,s2a_1layer_ckpt,s2a_full_ckpt\n","    # Clear any previously loaded models from memory\n","    clear_model_cache()\n","    time.sleep(5)  # Optional delay to ensure memory is fully cleared\n","    # Load configurations\n","    cfg_path = \"./models/tts/maskgct/config/maskgct.json\"\n","    cfg = load_config(cfg_path)\n","\n","    # Load models\n","    semantic_model, semantic_mean, semantic_std = build_semantic_model(device)\n","    semantic_codec = build_semantic_codec(cfg.model.semantic_codec, device)\n","    codec_encoder, codec_decoder = build_acoustic_codec(cfg.model.acoustic_codec, device)\n","    t2s_model = build_t2s_model(cfg.model.t2s_model, device)\n","    s2a_model_1layer = build_s2a_model(cfg.model.s2a_model.s2a_1layer, device)\n","    s2a_model_full = build_s2a_model(cfg.model.s2a_model.s2a_full, device)\n","\n","    # Load checkpoints\n","    safetensors.torch.load_model(semantic_codec, semantic_code_ckpt)\n","    safetensors.torch.load_model(codec_encoder, codec_encoder_ckpt)\n","    safetensors.torch.load_model(codec_decoder, codec_decoder_ckpt)\n","    safetensors.torch.load_model(t2s_model, t2s_model_ckpt)\n","    safetensors.torch.load_model(s2a_model_1layer, s2a_1layer_ckpt)\n","    safetensors.torch.load_model(s2a_model_full, s2a_full_ckpt)\n","\n","    #load Whisper\n","    model_id = \"openai/whisper-large-v3-turbo\"\n","    whisper_model = AutoModelForSpeechSeq2Seq.from_pretrained(\n","        model_id, torch_dtype=torch.float16, low_cpu_mem_usage=True, use_safetensors=True\n","    )\n","    whisper_model.to(device)\n","    processor = AutoProcessor.from_pretrained(model_id)\n","    whisper_pipe = pipeline(\n","        \"automatic-speech-recognition\",\n","        model=whisper_model,\n","        tokenizer=processor.tokenizer,\n","        feature_extractor=processor.feature_extractor,\n","        torch_dtype=torch.float16,\n","        device=device,\n","    )\n","\n","    return (semantic_model, semantic_codec, codec_encoder, codec_decoder,\n","            t2s_model, s2a_model_1layer, s2a_model_full, semantic_mean, semantic_std,\n","            whisper_model,whisper_pipe)\n","\n","\n","\n","def voice_clone(reference_path, text,duration=None):\n","    global semantic_model, semantic_codec, codec_encoder, codec_decoder\n","    global t2s_model, s2a_model_1layer, s2a_model_full, semantic_mean, semantic_std\n","    global whisper_model, whisper_pipe\n","    prompt_wav_path = process_audio(reference_path, max_duration=15)\n","    if is_gpu_memory_over_limit():\n","        print(\"Loading models due to GPU memory limit\")\n","        (\n","            semantic_model, semantic_codec, codec_encoder, codec_decoder,\n","            t2s_model, s2a_model_1layer, s2a_model_full, semantic_mean, semantic_std,\n","            whisper_model, whisper_pipe\n","        ) = load_model()\n","\n","    print(\"Processing reference audio:\", prompt_wav_path)\n","\n","    # Get the prompt text from the reference audio\n","    try:\n","        prompt_text = whisper_pipe(prompt_wav_path)['text'].strip()\n","    except Exception as e:\n","        print(f\"Error during transcription: {e}\")\n","        return None\n","\n","    print(\"Extracted prompt text:\", prompt_text)\n","\n","    # Set the target text\n","    target_text = text\n","\n","    # Check if the prompt_text and target_text are not empty\n","    if not prompt_text or not target_text:\n","        print(\"Prompt text or target text is empty.\")\n","        return None\n","\n","    # Create the inference pipeline\n","    maskgct_inference_pipeline = MaskGCT_Inference_Pipeline(\n","        semantic_model,\n","        semantic_codec,\n","        codec_encoder,\n","        codec_decoder,\n","        t2s_model,\n","        s2a_model_1layer,\n","        s2a_model_full,\n","        semantic_mean,\n","        semantic_std,\n","        device,\n","    )\n","\n","    try:\n","        recovered_audio = maskgct_inference_pipeline.maskgct_inference(\n","            prompt_wav_path, prompt_text, target_text, \"en\", \"en\", target_len=duration\n","        )\n","    except Exception as e:\n","        print(f\"Error during inference: {e}\")\n","        return None\n","\n","    # Save the output audio\n","    save_path = tts_file_name(text)\n","    sf.write(save_path, recovered_audio, 24000)\n","    print(f\"Audio saved to: {save_path}\")\n","    return save_path\n","\n","\n","\n","def voice_clone_long_text(reference_audio_path,text,input_duration):\n","  global base_path\n","  audio_list=[]\n","  temp_folder=f\"{base_path}/clone_voice\"\n","  if os.path.exists(temp_folder):\n","    shutil.rmtree(temp_folder)\n","  os.mkdir(temp_folder)\n","  sentences=chunks_sentences(text,join_limit=2)\n","  for index,sentence in enumerate(sentences):\n","    temp_path=voice_clone(reference_audio_path, sentence,duration=input_duration)\n","    temp_file=f\"{temp_folder}/{index}.wav\"\n","    shutil.move(temp_path,temp_file)\n","    audio_list.append(temp_file)\n","  cloned_voice_path=tts_file_name(text)\n","  merge_audio(audio_list, cloned_voice_path)\n","  return cloned_voice_path\n","\n","def gradio_app(reference_audio_path,text,input_duration,large_text):\n","  if input_duration==-1 or input_duration==0:\n","    Duration=None\n","  else:\n","    Duration=input_duration\n","  if large_text:\n","    cloned_voice_path=voice_clone_long_text(reference_audio_path,text,Duration)\n","  else:\n","    cloned_voice_path=voice_clone(reference_audio_path, text,duration=Duration)\n","  return cloned_voice_path\n","\n","\n","\n","# Call the function\n","# voice_clone(\"/content/reference.wav\", \"hi how are you guys\",duration=None)\n","\n","\n","# Load models for the first time, clearing any old models\n","(\n","    semantic_model, semantic_codec, codec_encoder, codec_decoder,\n","    t2s_model, s2a_model_1layer, s2a_model_full, semantic_mean, semantic_std,\n","    whisper_model,whisper_pipe\n",") = load_model()\n","\n","\n","reference_folder = f\"{base_path}/trim_audio\"\n","save_audio_folder=f\"{base_path}/clone_voice\"\n","os.makedirs(reference_folder, exist_ok=True)\n","os.makedirs(save_audio_folder, exist_ok=True)\n","\n","\n","\n","from IPython.display import clear_output\n","clear_output()"],"metadata":{"cellView":"form","id":"eXeccCJhyYoJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title Using Gradio Interface\n","import gradio as gr\n","\n","\n","gradio_inputs=[gr.Audio(label=\"Reference Audio\", type=\"filepath\"),\n","               gr.Textbox(label=\"Text to Generate\",lines=3),\n","               gr.Number(label=\"Target Duration (in seconds), if the target duration is less than 0, the system will estimate a duration.\", value=-1),\n","               gr.Checkbox(label=\"Long Text ?\",value=False)\n","              ]\n","gradio_outputs=[gr.Audio(label=\"Generated Audio\")]\n","demo = gr.Interface(fn=gradio_app, inputs=gradio_inputs,outputs=gradio_outputs , title=\"MaskGCT TTS English Demo \")\n","demo.launch(allowed_paths=[f\"{base_path}/clone_voice\"],debug=False,share=True)\n"],"metadata":{"cellView":"form","id":"gUWqYldo9Epu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Run From Colab Cell"],"metadata":{"id":"edbK08QVFEwT"}},{"cell_type":"code","source":["#@title Uplaod Reference Audio File\n","import os\n","from google.colab import files\n","from IPython.display import clear_output\n","\n","def upload_audio():\n","    upload_folder = f\"{base_path}/user_upload\"\n","\n","    # Ensure the upload folder exists\n","    os.makedirs(upload_folder, exist_ok=True)\n","\n","    # Change to the upload directory\n","    os.chdir(upload_folder)\n","\n","    # Upload the files\n","    uploaded = files.upload()\n","\n","    # Switch back to the original install directory (ensure install_path is defined)\n","    os.chdir(project_path)\n","\n","    audio_name_list = []\n","\n","    for fn in uploaded.keys():\n","        file_path = f\"{upload_folder}/{fn}\"\n","        save_file_path = clean_file_name(file_path)\n","\n","        # Rename the file with cleaned file name\n","        os.rename(file_path, save_file_path)\n","        audio_name_list.append(save_file_path)\n","\n","    # Filter audio files based on valid audio extensions\n","    audio_extensions = ('.wav', '.mp3')\n","    valid_audio_files = [f for f in audio_name_list if f.lower().endswith(audio_extensions)]\n","\n","    # Clear the output (for Google Colab)\n","    clear_output()\n","\n","    if valid_audio_files:\n","        # Return the first valid audio file found\n","        return valid_audio_files[0]\n","    else:\n","        # Print message if no valid audio files were uploaded\n","        print(\"Please upload an audio file.\")\n","        return None\n","upload_audio()"],"metadata":{"cellView":"form","id":"UoLKIPvL-PxX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["TTS_Duration: 0 mean None , the system will estimate a duration.\n"],"metadata":{"id":"vnVZbmbfGddG"}},{"cell_type":"code","source":["#@title Generate TTS\n","Reference_Audio_Path= '/content/anime.mp3'  # @param {type: \"string\"}\n","Text_to_Generate= \"What kind of story would you like? Fantasy, sci-fi, adventure, or maybe something heartwarming or mysterious? And do you want it to be short or longer? Let me know any details you want, and I'll dive right in!\"  # @param {type: \"string\"}\n","TTS_Duration = 0  # @param {type: \"number\"}\n","Large_Text = 0  # @param {type: \"boolean\"}\n","cloned_voice_path=gradio_app(Reference_Audio_Path,Text_to_Generate,TTS_Duration,Large_Text)\n","from IPython.display import clear_output\n","clear_output()\n","print(f\"TTS Save at {cloned_voice_path}\")\n","from IPython.display import Audio\n","Audio(cloned_voice_path)"],"metadata":{"cellView":"form","id":"t_zs3Rp9-nOc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title Download Cloned Voice\n","from google.colab import files\n","files.download(cloned_voice_path)"],"metadata":{"cellView":"form","id":"yN1GK_s9GOcV"},"execution_count":null,"outputs":[]}]}